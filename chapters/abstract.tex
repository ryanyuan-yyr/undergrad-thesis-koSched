% !TeX root = ../main.tex

\ustcsetup{
  keywords  = {CUDA，内核分割，并行计算，搜索算法},
  keywords* = {CUDA, kernel slicing, parallel computing, searching algorithm},
}

\begin{abstract}
  得益于高计算性能和低能源消耗，图形处理器（GPU）广泛用于科学计算。已有研究表明，不同的CUDA内核在执行过程中需要不同的资源，因此使不同类型的CUDA内核并行运行可能实现性能提升。由于NVIDIA设备的调度策略难以实现多内核并行，一些开发人员使用内核分割技术将单个内核划分为较小的子内核来实现内核并行，从而实现更好的资源利用和程序性能。然而，子内核尺寸的不当选择可能会导致性能提升极其有限甚至不升反降。在本文中，我们提出了\emph{ko-Sched}，一种基于搜索的子内核配置调整工具，以适应不同内核的资源要求并最大化资源利用和程序性能。我们使用现实中的应用程序进行了大量的性能评估来展示我们方法的有效性。我们的结果表明，通过采用我们的算法进行内核分割后，测试程序在多种GPU硬件下平均能达到$12.5\%$的性能提升，部分程序的性能提升可达到$30\%$。这表明我们的方法可以帮助开发人员优化其应用程序。我们的贡献包括为开发人员提供一个编写子内核尺寸可变的CUDA程序的框架和使用搜索算法为每个内核找到最佳的子内核配置的工具。
\end{abstract}

\begin{abstract*}
  Graphics Processing Units (GPUs) are widely used for scientific and technical computations due to their high computational performance and energy efficiency. Previous studies have shown that different CUDA kernels require different types of hardware resources during execution, and parallel execution of different types of CUDA kernels can lead to performance improvements. However, the scheduling policy of NVIDIA devices makes it difficult to parallelize different kernels. Some developers use kernel slicing techniques to divide a single kernel into smaller sub-kernels in order to achieve kernel parallelization, resulting in better resource utilization and performance. Unfortunately, improper configuration of sub-kernel size can lead to limited performance gains or even performance degradation. In this paper, we propose \emph{ko-Sched}, a searching-based configuration tuner that accommodates the resource requirements of different kernels and arranges them to maximize resource utilization and performance. We demonstrate the effectiveness of our approach through extensive performance evaluations using real-world applications and show that our approach achieves significant performance improvement. Our results show that, by adopting the configuration advised by our framework, the benchmark programs can achieve an average performance improvement of $12.5\%$ on various GPU hardware, and some programs can even achieve a performance improvement of up to $30\%$, indicating that our approach provides a valuable tool for developers seeking to optimize their applications. Our contributions include providing a convenient framework for developers to write size-variable kernels and using a searching algorithm to find the optimal sub-kernel configuration for each kernel. 
\end{abstract*}
